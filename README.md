# ğŸš€ Automated S3 Data Pipeline

## ğŸ“ Overview

This project showcases a **production-ready serverless pipeline** built on **AWS**, designed to automatically process files uploaded to **Amazon S3**.  
Whether itâ€™s structured data (CSV) or unstructured image files, the pipeline intelligently routes and processes themâ€”no servers, no stress.

Perfect for **developers**, **data engineers**, or anyone who wants to automate file processing like a pro.

---

## ğŸŒŸ Features

âœ… **Dual File Type Support** â€“ Instantly detects and processes both CSV files and images  
âœ… **CSV Processing** â€“ Parses data, generates statistics, and outputs formatted reports  
âœ… **Image Resizing** â€“ Automatically creates optimized versions: `thumbnail`, `medium`, and `large`  
âœ… **Real-time Notifications** â€“ Sends email alerts via **Amazon SNS** when processing completes  
âœ… **Serverless Architecture** â€“ Zero server management, infinite scalability  
âœ… **Cost Effective** â€“ Pay-per-execution (AWS Free Tier friendly)  
âœ… **Production Ready** â€“ Includes error handling, logging, and monitoring baked in

---

## ğŸ§  Architecture

```

User Upload â†’ S3 Bucket (uploads/) â†’ Lambda Function â†’ Process File â†’ S3 (processed/) â†’ SNS â†’ Email
â†“
Event Trigger
â†“
[File Type Detection]
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â†“ â†“
CSV Processor Image Processor
â†“ â†“
Text Report Resized Images (3 sizes)

```

---

## ğŸ›  Setup Instructions

1. **Clone the repository**

```bash
git clone <repository-url>
cd s3-data-pipeline
```

2. **Install dependencies** (for local testing)

```bash
pip install -r requirements.txt
```

> `boto3` is already available in AWS Lambda environments.

3. **Configure Environment Variables** in Lambda:

- `SNS_TOPIC_ARN`: The ARN of your SNS topic for notifications.

4. **Deploy Lambda Code** to AWS:

- Zip the folder and upload via the AWS Lambda Console,
  **or** integrate with your preferred CI/CD pipeline.

---

## âš¡ Usage

1. Upload a CSV file or image to the S3 bucket under the `uploads/` folder.
2. Lambda triggers automatically on upload.
3. Depending on file type:

   - **CSV** â†’ Parsed â†’ Stats generated â†’ Saved as `processed/<filename>_report.txt`
   - **Image** â†’ Resized into `thumbnail`, `medium`, `large` â†’ Saved to `processed/`

4. SNS sends you an email with processing detailsâ€”like magic âœ¨

---

## ğŸ§  Figma Design

Take a peek at the **architecture and flow** here:
ğŸ‘‰ [**View Figma Design**] https://lnkd.in/dauzaqxf

---

## ğŸ“½ Demo Video

See the pipeline in action:
ğŸ‘‰ [**Watch the Demo on YouTube**] https://lnkd.in/dzYt9Haz

---

## ğŸ¤ Contributing

1. Fork the repository.
2. Create a feature branch:

```bash
git checkout -b feature/new-feature
```

3. Make your changes and commit:

```bash
git commit -m "Add new feature"
```

4. Push to your branch:

```bash
git push origin feature/new-feature
```

5. Open a **Pull Request**.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
Feel free to build on it, remix it, and ship cool things ğŸš¢
